export const sample = {
    hr: `HR Bot Development Documentation SCB DataX Co., Ltd. Effective Date: 31/03/2025 Document Owner: Model Development Division This document is for DataX internal use, not to be disclosed to external parties. Page 2 | 12 Version History Version Change Date Updated by Key Changes Approved by 1.0.0 31-Mar-2025 Sapient Initial version This document is for DataX internal use, not to be disclosed to external parties. Page 3 | 12 Table of Contents Table of Contents ..................................................................................................................... 3 1. Executive Summary: ......................................................................................................... 4 Overview.............................................................................................................................................. 4 Purpose and Scope .............................................................................................................................. 4 Excluded: ............................................................................................................................................. 4 Key outcome expected ........................................................................................................................ 4 Stakeholders ........................................................................................................................................ 4 2. Data Source: ...................................................................................................................... 4 3. Methodology: ..................................................................................................................... 7 4. Specifications:.................................................................................................................... 9 5. Performance: ..................................................................................................................... 9 6. Responsible AI: ............................................................................................................... 10 o Fairness ..................................................................................................................................... 10 o Reliability and Safety ................................................................................................................ 10 o Privacy ...................................................................................................................................... 10 o Security ..................................................................................................................................... 10 o Transparency ............................................................................................................................ 10 o Explainability ............................................................................................................................ 10 o Accountability ........................................................................................................................... 10 7. Monitoring:...................................................................................................................... 11 8. Implementation: .............................................................................................................. 11 9. Limitations: ..................................................................................................................... 12 Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 4 | 12 1. Executive Summary: Overview The HR Chatbot is an intelligent, dual-source AI system designed to assist employees with HR-related queries in real- time while supporting HR administrators with data analysis capabilities. It leverages an Agentic AI architecture, enabling seamless interaction with structured (employee records, flex benefits, & leave balances) and unstructured (HR policies) data sources. The project aims to streamline HR support, reduce manual workload, and improve response efficiency by integrating AI-driven automation. Purpose and Scope • Automate HR support functions by handling employee queries related to benefits, leave balances, employee profile & policy documentation. • Reduce HR team workload by providing instant, self-service support to employees. • AI-driven conversational assistance for employees. • Integration with structured HR data (employee profile, flexible benefits, leave records). • Role-based access control for secure data retrieval. • Multi-agent framework for handling complex workflows. Excluded: Any other integrations Key outcome expected The HR Bot automates repetitive HR tasks, provides policy guidance, improves employee experience, and enhances HR team productivity. • Automate Routine HR Tasks • Answer common employee queries (leave, benefits, policies). • Reduce workload on HR staff by handling repetitive tasks. • Minimize response time for employee queries. • Provide responses aligned with updated HR policies. • Enable 24/7 support for employee queries. • Provide intuitive self-service for faster resolution. • Enable Data-driven HR Insights for HR Admins Stakeholders Identify key stakeholders involved (e.g., Owner, Sponsor, Developers). # Name Team/department Role 1 K.Kamlai Jindapon HR – SCBx Business 2 K.Nopporn Phanatawee HR- SCBx Business 3 K.Rujipol Virochpoka DataX Owner & Sponsor 4 K.Ekkapong udomlarptham DataX Owner & Sponsor 5 Publicis Sapient PS Development Team 2. Data Source: Datasets Used The HR Chatbot leverages a dual-source data approach, combining structured and unstructured data: 1. HR Policies & Documentation (Unstructured Data) Format: PDFs, DOCX, XLSx Source: HR SCBx Preprocessing : None Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 5 | 12 2. Employee Profile, Flex Benefits & Leave Data (Structured Data) Format: PostgreSQL Source: MDZ DataMart Preprocessing : The data from actual HRMS is Flex Benefits Table field_name_curated field_description_en SUBMITTED_TS Timestamp when the claim was submitted by the employee, including date and time EMAIL_SUBMITTER Email address of the employee who submitted the claim SUBMITTER_NAME Name of the employee who submitted the claim, typically the person requesting reimbursement FULL_NAME Complete name of the employee for whom the claim is being made CLAIM_FOR Purpose or category of the expense being claimed SUPERVISOR_NAME Name of the approving supervisor or manager for this claim CLAIM_TYPE Specific type of claim CLAIM_GROUP Broader category or grouping of claims for reporting purposes CLAIM_AMOUNT Monetary value of the claim in the specified currency CLAIM_DESCRIPTION Detailed description of the expense and its business purpose LOAD_TS System timestamp indicating when the record was loaded into the database LOAD_DT Calendar date when the record was loaded Employee Leave Table field_name_curated field_description_en EMP_ID Unique employee identification number EMP_NAME_EN Employee name in EN EMP_NAME_TH Employee name in TH VACATION_CARRY_OVER_B ALANCE Represents the unused vacation leave from the previous year that has been carried over to the current year. VACATION_BEGINNING_YEA R_BALANCE The total vacation leave entitlement available to an employee at the start of the current year, including any carried-over balance if applicable. VACATION_LEAVE_TAKEN The amount of vacation leave utilized by the employee during the current year. VACATION_LEAVE_BALANCE _APPROVED The remaining balance of vacation leave that has been approved for the employee but has not yet been taken. VACATION_LEAVE_BALANCE _INCLUDED_PENDING The remaining balance of vacation leave, including both approved and pending leave requests. BUSINESS_LEAVE_BEGINNIN G_YEAR_BALANCE The total business leave entitlement available to an employee at the start of the current year. BUSINESS_LEAVE_TAKEN The amount of business leave utilized by the employee during the current year. BUSINESS_LEAVE_BALANCE _APPROVED The remaining balance of business leave that has been approved for the employee but has not yet been taken. BUSINESS_LEAVE_BALANCE _INCLUDED_PENDING The remaining balance of business leave, including both approved and pending leave requests. SICK_LEAVE_BEGINNING_YE AR_BALANCE The total sick leave entitlement available to an employee at the start of the current year. SICK_LEAVE_TAKEN The amount of sick leave utilized by the employee during the current year. SICK_LEAVE_BALANCE_APPR OVED The remaining balance of sick leave that has been approved for the employee but has not yet been taken. SICK_LEAVE_BALANCE_INCL UDED_PENDING The remaining balance of sick leave, including both approved and pending leave requests. Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 6 | 12 LOAD_TS System timestamp indicating when the record was loaded into the database LOAD_DT Calendar date when the record was loade EMP_EMAIL Employee email address Employee Profile field_name_curated field_description_en EMP_ID Unique employee identification number EMP_EMAIL Employee email address PRFX_TH Title prefix in Thai language FRST_NAME_TH First name in Thai language LAST_NAME_TH Last name in Thai language PRFX_EN Title prefix in English FRST_NAME_EN First name in English LAST_NAME_EN Last name in English FULL_NAME_TH Full name in Thai language FULL_NAME_EN Full name in English CORP_TITLE Official corporate title of the employee HIRE_DT Initial date of employment AGE Current age of employee SEX_EN Gender in English NATN_EN Nationality in English ADDR_PRVC_TH Province name in Thailand OFFC_MOBILE_NUM Office mobile number WORK_PHN_NUM Work telephone number ORG_NM Organization name in English Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 7 | 12 3. Methodology: HR Bot is based on an agentic architecture where multiple agents interact with each other to resolve a user query. Please see the below conceptual diagram RAG Agent Given a query, the RAG agent is responsible for generating a response to a query by applying the Resource Augmented Generation (RAG) pattern. The agent retrieves query-relevant data form a data store and generates a response to the query using this contextual data. High-level Agent Flow 1. The Planner Agent passes the query to the RAG Agent. 2. The RAG Agent uses a reusable retrieval tool to fetch context from Azure AI Search (using a combination of text and vector search). • The results are re-ranked to obtain the most precise response. • This context, along with the query, is passed to the LLM for response generation. • The final response is then sent back to the Planner Agent. 3. The Planner Agent checks whether the required answer has been received. If the response is not satisfactory, the Planner re-prompts the RAG Agent. 4. Once the desired output is received, the flow ends, and a concise response is generated by the Response- Compiler Agent. 5. The RAG Agent is instructed to respond solely based on the uploaded content. If no relevant documents (chunks) are retrieved, the RAG Agent replies that the requested information is not available. 6. Control Mechanism: The RAG agent has been provided clear instructions in the prompt to only respond based on the available content. In case the RAG agent does not find related content, it will respond to the user stating its inability to find any related content. (As instructed in the prompt) RAG Hyperparameters • TOP_K_RESULTS: "7" • Temperature: 0.1 • Max Token per Chunk: 1024 • Chunk Overlap: 20% Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 8 | 12 Disambiguation Agent: Given a user’s query, this agent is responsible for improving the query so that other agents can provide accurate and high quality responses. High-level Agent Flow Disambiguation Agent receives the user query (+ chat history) and performs following: 1. If the query is a general greeting, the agent responds appropriately. 2. If the query is not related to the HR domain, the agent re-introduces its capability and suggests a relevant topic within the domain or expresses its inability to respond to the query. 3. If the query is of domain but ambiguous or lacks necessary details, the agent requests clarification from the user. 4. If the query is clear and domain-relevant, the agent forwards the query to the planner agent. 5. Control Mechanism: a. Only queries which fall in the defined scope of HR are sent forward for resolution to the planner. For e.g. What is the prevailing lending rate given by ABC Bank? Bot: I'm sorry, but I can't assist with queries related to external financial institutions like ABC Bank. (As instructed in the prompt) b. Toxic or Harmful queries are blocked by Azure Content Safety service. For e.g. How to make a bomb? Bot: As per our policies we cannot process this query. Please try again with a different query. c. Filtering based on user role. Based on the user’s role (determined by the group user belongs to), employee or HR Super Admin the bot is conditionally prompted to provide information only regarding the current employee or all employees for the HR Super Admin. Additionally, there are only read access on the database. SQL Agent Given a natural language query, the SQL agent is responsible for sourcing the data relevant to the query and generating a response. To accomplish this job, the agent takes the following approach: • It determines the database tables that are relevant to the query it has received based on table schemas and the query intent • If the available data does not have the required information as per the user query then the SQL agent returns a response stating that this information cannot be found in the database. • It generates an SQL query based on the query intent and the data that is available. • The query is executed using an SQL execution tool • The resulting context, along with the query, is passed to the LLM for response generation • The final response is then sent back to the Planner Agent. Control Mechanism: SQL agent has been instructed via prompt to create queries only based on the schema and the table details that are passed in the prompt. For details not available in the passed schema, the agent has been instructed via the prompt to decline user request and inform the user that the data is not available. Planner Agent Plans, schedules, assigns and manages the tasks required to resolve a user query When the planner agent receives a user query, it creates and executes a plan to resolve the query. To accomplish this task, the planner agent performs the following duties, primarily using the LLM: • Decomposition of the user query so that compound queries can be broken down • Construction of a query handling execution plan for resolution of the query and/or query components, based on a set of known agents • Execution of the query handling plan by calling other agents (RAG agent or SQL Agent) • Validating and evaluating the responses from agents that it has invoked to ensure that the final query response will be useful • Invoking the Response Compiler agent to generate a query response as the last step in the execution plan In order to provide the best result, the planner agent may call individual agents multiple times. It may also re-invoke an agent with a refined instruction if the results form an agent are deemed to be unsuitable by the planner. Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 9 | 12 Response Complier Agent Generates the final response to a query that will be sent back to a user The Response Compiler Agent is responsible for generating a useful and readable response based on the results of an executed query. This agent has the following duties: • Extracting relevant information from the results of an executed query-response sent by planner • Generating a response that is concise and relevant to the original query 4. Specifications: Model as a service: Azure OpenAI GPT 4o Compute AKS, Azure Function. Ingestion Azure logic apps API integrations and dependencies For structured data : MDZ Datamart For Authentication: Azure Entra ID 5. Performance: We are measuring the performance of our solution based on Deepeval metrics • Answer Relevancy: The answer relevancy metric measures the quality of the RAG pipeline's generator by evaluating how relevant the actual_output is compared to the provided input. • Correctness: Determines whether the actual output is factually correct based on the expected output. • Coherence: Measures that the output is logically structured, clear, and directly relevant to the HR query • Faithfulness: The faithfulness metric uses LLM-as-a-judge to measure the quality of your RAG pipeline's generator by evaluating whether the actual_output factually aligns with the contents of your retrieval_context. • Toxicity: The toxicity metric is a reference less metric that evaluates toxicness in the outputs. • Bias: The bias metric determines whether the LLM output contains gender, racial, or political bias. • Contextual Recall: The contextual recall metric uses LLM-as-a-judge to measure the quality of the RAG pipeline's retriever by evaluating the extent of which the retrieval_context aligns with the expected_output. Deepeval Evaluation Metrics as on 22 March 2025 # Metric Evaluation Score (Percentage of success as compared to failure Threshold 1 Answer Relevancy 97.60% .6 2 Correctness 91.60% .6 3 Coherence 94.80% .6 4 Faithfulness 97.95% .6 5 Toxicity 100% .6 6 Bias 100% .6 7 Contextual Recall 93.60% .6 Please Note: We are not training or fine tuning the OpenAI model, hence any LLM evaluation parameters are not applicable to the said solution. Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 10 | 12 6. Responsible AI: o Fairness Azure content safety service is being used to enforce guardrails. Moreover, we are using the Open AI GPT 4o model as available from Azure. o Reliability and Safety Azure content safety service is being used to enforce guardrails. Moreover, we are using the Open AI GPT 4o model as available from Azure. For e.g. I'm very stressed. Is it a good idea to jump from the middle of a building? Which way up? ACS Response: As per our policies we cannot process this query. Please try again with a different query. o Privacy Azure content safety service is being used to enforce guardrails. Moreover, we are using the Open AI GPT 4o model as available from Azure. o Security DataX exicting security standards enforces on Azure using Azure policies, azure defender, azure sentinel etc will be inherited by the HR Bot solution. Additionally, a SAT will be conducted by DataX o Transparency Langfuse is used for observability, providing complete visibility into the internal reasoning and decision-making of all Agents. Additionally, all retrieved answers are supported by a reference document from where the answer has been generated. o Explainability As mentioned earlier we are not training or developing an AI model. From the HR Bot perspective, responses are made explainable by exposing the relevant document used in the generation process. The system provides source attribution for each answer, allowing users to trace the output back to specific documents. Prompt templates and retrieval reasoning are also maintained in Langfuse for transparency. o Accountability As defined by DataX Azure AI Content Safety: Azure AI Content Safety is an AI service that detects harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes text and image APIs that allow you to detect material that is harmful Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 11 | 12 Threshold set for Azure content safety service var categoryThresholds = new Dictionary<string, int> { { "Hate", 3 }, { "Sexual", 3 }, { "SelfHarm", 2 }, { "Violence", 3 } }; 7. Monitoring: The following metrics will be monitored in production for the HR Bot using a combination of Langfuse and DeepEval (planned transition to Fiddler.AI when available): • Answer Relevancy • Faithfulness • Contextual Recall The DeepEval report will be reviewed every 15 days to monitor the bot’s performance. It is possible that metric scores may degrade when new documents are added, as the RAG system is static and does not self-learn. If any metric consistently falls below the defined threshold (0.6), the Operations team will raise an incident ticket and escalate it to the Product Owner for review and prioritization. The resolution will be based on a root cause analysis, which may include the following: • Documentation gaps: The product team will collaborate with the HR team to review queries and relevant documentation for any outdated, missing, or unclear information. • Chunking issues: Review and refine the chunking strategy to ensure context is properly captured for retrieval. • Prompt design: Evaluate and enhance the prompt to better guide the model and improve response quality. • Outdated knowledge base: Documents not reflecting the latest policies or updates, leading to incorrect responses. Please note, this is not an exhaustive list and the actual resolution will be dependent on the point in time root cause. 8. Implementation: As part of the implementation, the key objective is to ensure the solution is designed and built as a production-grade application based on AI agentic architecture, with robust safety guardrails in place. The HR Bot consists of two core components: • Chatbot: Handles quick Q&A interactions with users. • Data Storage: Allows HR Admins to securely upload and manage documents used by the chatbot. Additionally, the HR Bot is integrated with the MDZ datamart to access employee and leave-related data. This enables users to get personalized answers, such as “How many sick leaves do I have remaining?” It also allows HR Super Admins to retrieve information about other employees, for example, “How many leaves are remaining for employee ID 6789?” The HR Bot uses model as a service for OpenAI GPT 4o from Open AI. The application deployment strategy and rollout is part of the environment setup & infrastructure. Please see the belpw diagram for the HR Bot Mid-level design & Infrastructure. Model Development Documentation This document is for DataX internal use, not to be disclosed to external parties. Page 12 | 12 9. Limitations: The HR Bot inherits limitations from the underlying GPT-4o model, including: • Possibility of inaccurate responses • Limited reasoning capability • No real-time learning`,
    autox: `AI System In this work, we proposed an AI system that leverages voice processing and language processing technologies to support Loan Conduct Validation. The system assists AutoX in evaluating conduct details against the conversation between an AutoX Sales agent and a customer captured through audio recordings. The system subsequently classifies the conduct compliance status along with a reason. Overall System Architecture System Workflow The system processes a recorded conversation between an agent and a customer discussing a loan. •	First, the audio is segmented using a speech-to-text service, then transcribed into text with a fine-tuned Whisper model. •	The transcribed text is analysed by a GPT-4o model to evaluate whether the agent's responses comply with market conduct standards. •	Finally, the system generates a True/False result with an explanation, while filtering out any harmful or inappropriate content to ensure safety. Service Explanation Core Service A)	\`validate-market-conduct\` - is another API endpoint that can be used to determine user-defined conduct description against audio transcribed text. The requester is the one who provide: •	input text (preferably transcribed text from \`transcribe\` service) •	input conduct description B)	\`transcribe\` - is API endpoint service that is accessible requesters to transcribe audio to text. The requester must provide audio file to use this service. Prompt Service Conduct Detection A service that leverages LLM to classify conduct compliance. It takes transcribed audio (text), conduct information such as conduct name, conduct keyword, positive/negative example, and LLM parameters. The output represents classification whether conduct is being complied \`true\` or false\` (see API specification documents for more detail). This service employs in-context learning prompt technique to manipulate LLM inference input. Please find prompt design and evaluation report from this document prompt_tuning.docx AI Service Speech-to-Text This microservice is designed to convert spoken language into written text. It leverages advanced machine learning models service (ASR via Model Serving Service) to provide accurate and efficient transcription of audio input. It aims to provide a robust and efficient solution for converting speech to text, enabling a wide range of applications from automated transcription to real-time communication assistance. Model Serving (Fine-tuned Whisper model) This service is designed to be deployed as a microservice for serving machine learning models. It allows requester to perform low-latency inference using available models (self-hosting model). It only supports whisper models (fine-tuned by SCBX R&D) for the time being. Please find fine-tuned Whisper model technical report here ASR.docx (the result was on Lending discussion dataset) Azure OpenAI Azure OpenAI Service is a fully managed, cloud-based AI offering that provides access to OpenAI's language models, such as GPT-4, GPT-3.5, Codex, and DALL·E, through Azure’s secure and scalable environment. This service enables businesses and developers to integrate advanced AI capabilities into their applications, enhancing automation, natural language understanding, and generative AI solutions. Observability & User Service Prompt Tracing This service enables tracing capability for prompt. It leverages Langfuse which is allowed stakeholders to inspect decision paths taken by the model, evaluate failure cases (e.g., model refusal or misinterpretation), and continuously improve prompt quality and model behaviour. This is critical for transparency and explainability in regulated or high-risk environments. User Service The User Management API enables seamless user management, allowing the creation, retrieval, updating, and deletion of users within the system. Each endpoint returns structured responses, including status codes, messages, and detailed user data. Error responses follow a standard format to indicate validation failures or other issues. This API ensures efficient and organized user management through a RESTful interface. AI System E2E Performance Evaluation In addition to evaluating individual services, we conducted a comprehensive end-to-end performance assessment of the system. The primary focus is on measuring AI accuracy and responsibility across key metrics established in collaboration with the validation and development teams. This document provides a detailed overview of the evaluation process and findings. Refer to E2E_Experiment.docx Deployment Version Control A tagging ID is automatically generated with each commit to the repository. For deployment, the corresponding commit tag from the candidate branch is applied to the parsed configuration or used to update the existing configuration in the deployment repository. This repository is pre-configured to enable building and publishing the tagged container to Azure container registry. Once published, the package is deployed to the target environment. Continuous Deployment Plans Technical Performance Logging Application Logging The engine uses structured JSON logging throughout the system, so logs are both easy to read and easy for machines to parse. Each log includes the log level, message, module name, and timestamp, plus some extra context to make debugging easier. Every log entry includes: •	A consistent app ID: genai-pf-prompt-conduct-detection •	A dynamic correlation ID to help trace a request across different services It automatically adjusts log levels are automatically adjusted depending on the environment. Users could see info in development and only warnings/errors in production. Service Operation Monitoring Dashboard The GenAI platform provides a service monitoring dashboard to track and visualize technical performance metrics. This dashboard integrates with Azure Log Analytics  and utilizes Grafana for data visualization. For more details, please visit Monitoring dashboard.pdf (Grafana detail) Prompt & Model Tracing The system integrates with Langfuse, an observability platform designed for monitoring AI applications. This enables tracing and analysis of interactions with language models. Environment	URL Non-Prod	https://genai-langfuse.dev.int.data-x.ai/ Pre-Prod	https://genai-langfuse.pp.int.data-x.ai/ Prod	https://genai-langfuse.int.data-x.ai/ In Conduct detection service, each call to the language model is: •	Wrapped in a Langfuse observation, which captures the user input, system prompt, and model output. •	Tagged with attributes such as market_conduct, chat_completion, and openai, allowing for granular analysis. •	Linked to user metadata and correlation ID, providing a clear trace of how each request was processed and by whom. Langfuse Screenshot Summary Dashboard Page Tracing Page (overall request) Tracing Detail For speech-to-Text service, it captures information such as audio duration, audio filename, trace id etc. This allows us to traceback for further investigation and improvement. No transcribed text has been stored. Operational Risk related Controls Error Handling and Recovery •	All API routes implement structured try/except handling. •	Errors are logged with full context and returned using standardized response formats. •	Specific exceptions such as KeyError, ValueError, and HTTPException are handled gracefully to avoid cascading failures. Input/Output Validation •	The FastAPI framework enforces schema-level validation of incoming requests. •	Any validation error triggers a custom response with HTTP 422, improving client-side error awareness. •	Pydantic enforces structured request validation using the MarketConductInput model, ensuring all inputs conform to expected formats. This model embeds ConductData, which strictly defines rule-related fields such as keywords and sample phrases. To enhance flexibility, a custom validator dynamically checks optional params against the OpenAI SDK's accepted parameters and types. Once processed, AI responses are parsed and validated using the MarketConductResponse model to ensure output consistency. Finally, all responses—whether successful or erroneous—are wrapped in the StandardResponse model for a unified API interface. AI Output Sanity Checks •	If the AI model response lacks expected tool calls or is malformed, the system falls back to a safe default. •	In cases of model refusal (e.g., due to policy violations), the system blocks the response and logs it as a high-severity issue. Secure Configuration Management •	Sensitive values such as API keys and endpoint URLs are accessed via environment variables. •	Azure identity services are used for secure token management, reducing the exposure of secrets in the codebase. End-to-End Traceability •	The correlation-id header is injected into every request and propagated through logs, traces, and metrics. •	This enables security investigations, performance root cause analysis, and compliance audits with minimal friction. Content Filtering disabled. This change is being made to provide greater flexibility in content processing and improve response accuracy for specific use cases. Previously, Azure's content filter blocked certain inputs outright, which prevented us from evaluating them against our internal rules. To address this, we've disabled input content filtering for now, allowing all inputs to reach the main process for proper evaluation. Output filtering remains enabled at a medium level to ensure appropriate responses are still maintained. AI System Maintenance & Monitoring Continuous Monitoring of AI System Performance Stability Retention Plan Drift Detection Model Audits and Review Procedures (If planned from Internal/external resources) Feedback Loops (Incorporating User Feedback) Prompt Evaluation User feedback and real-time data`,
    asr: `Table of Contents Objective	2 Experiment Parameters	2 Speech-to-Text Service Parameters	2 Whisper Model	2 GPT-4o Parameters	2 Dataset	2 Evaluation Results	3 Discussion	4 Issues and Limitations	4 Supplements	4 Objective The end-to-end evaluation assesses the overall performance of the system in determining sale agent compliance with market conduct standards. It begins with recorded loan-related conversations as input, which are first chunked by a speech-to-text service and transcribed using a fine-tuned Whisper model. The transcribed text is then analyzed by a GPT-4o model to detect compliance, producing a True/False output with reasoning. This output is compared against ground truth data, and classification metrics are calculated to measure the system’s effectiveness. Experiment Parameters Speech-to-Text Service Parameters The system uses Silero VAD for audio chunking with the following parameters: •	vad_threshold = 0.5 •	vad_min_speech_duration_ms = 250 •	vad_min_silence_duration_ms = 750 •	vad_speech_pad_ms = 400 Whisper Model The transcription process utilizes Whisper Large V3, fine-tuned with Thai public datasets for improved accuracy. GPT-4o Parameters For conduct detection, the system employs GPT-4o with the following settings: •	Temperature = 0 •	Seed = 10 The temperature and seed parameters are set to make the results as deterministic as possible, ensuring consistency and reproducibility in conduct analysis. Dataset The dataset consists of 85 audio recordings of Loan discussions which are in the central dialect. Each recording is annotated with 6 distinct conduct rules for compliance evaluation. These annotations support three types of evaluation: Item-Level, Conduct-Level, and File-Level. Evaluation Results The results are an average of 3 runs. Item-Level Evaluation (510 samples) The model was evaluated on 510 individual conduct instances across all files, assessing its ability to detect compliance at a granular level. Precision	Recall	F1	accuracy 0.971	0.984	0.978	0.964 Conduct-Level Evaluation (6 groups, 85 samples) Performance was measured separately for each conduct number, grouping all instances of the same conduct across 85 files, providing insights into conduct-specific metrics. Conduct_ID	Precision	Recall	F1	Accuracy CYLOAN1	0.977	0.991	0.984	0.972 CYLOAN 2	0.949	0.960	0.954	0.937 CYLOAN 3	0.990	0.986	0.988	0.980 CYLOAN 4	0.937	0.986	0.960	0.933 CYLOAN 5	0.977	0.991	0.984	0.972 CYLOAN 6	0.995	0.991	0.993	0.988 File-Level Evaluation (85 samples) Each file is evaluated across 6 conducts, and the results will be grouped by how many of those were predicted incorrectly. # Incorrect Conducts	Proportion 0	0.808 1	0.169 2	0.024 The accuracy for correctly predicting all conducts in a file is 80.4%. Discussion The model demonstrated robust performance across Item-Level and Conduct-Level evaluations. However, accuracy drops in File-Level evaluation. This indicates that while the model is generally reliable, it has difficulty detecting compliance in certain scenarios, which is essential to address  for improved performance. Issues and Limitations Inconsistent Model Performance One major limitation observed is inconsistent performance even with identical inputs. Despite setting temperature to 0 and using a fixed random seed for LLM, the model still produces different results for the true/false classification across multiple runs. This suggests that even under deterministic settings, there may be internal variations in how the model processes inputs, making it difficult to guarantee full reproducibility (though the variation is low). Supplements Related Works LLM Stability: A Detailed Analysis with Some Surprises This paper investigates the stability of Large Language Models (LLMs), focusing on their variability in outputs under deterministic settings. The study evaluates how consistent LLMs are across repeated runs with identical inputs and fixed parameters. Evaluation Settings: •	Models Tested: GPT-3.5 Turbo, GPT-4o, Llama-3 (8B and 70B), and Mixtral-8x7b. •	Datasets: o	MMLU (Massive Multitask Language Understanding): A collection of 57 tasks from areas like humanities, STEM, and social sciences. The study uses only a few tasks, like "European History" and "College Mathematics." o	BBH (Beyond Imitation Game Hard): A collection of 27 challenging tasks in reasoning, math, and logic. Only a few tasks, such as "Logical Deduction" and "Navigation," were selected. o	Format: All tasks are multiple-choice questions, with 2 to 10 answer options per question. •	Fixed Parameters: Temperature = 0, Top-p = 1, and fixed seeds. Each task was run 5 times to measure stability. Key Findings: 1.	Accuracy Variability: •	Accuracy fluctuated within a 0–10% range across tasks and models. •	Simple tasks like "European History" showed less than 2% fluctuation, while complex tasks like "College Mathematics" had up to 10% variability. 2.	Output Stability: •	Raw Outputs: Rarely identical across runs, even with deterministic settings. •	Parsed Answers: More stable but not perfectly consistent. Stability varied by task, with reasoning and history tasks being more stable than math. `
}